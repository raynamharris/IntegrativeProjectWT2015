---
title: "Behavior Data Analysis"
output: md_document
---

This markdown file is used for behavioral data wrangling, statistical analysis, and data visualization. Figures from this analysis were assembled into this multi-panel plot using Adobe Illustrator. Files used to create the individual figures are saved in the data subdirectory with the prefix 01a.


## Setup

```{r setup, message=F}
## load libraries 
library(tidyverse) ## for respahing data
library(plyr) ## for renmaing factors
library(reshape2) ## for melting dataframe
library(cowplot) ## for some easy to use themes
library(factoextra)  ##pca with vectors
library(car) ## stats
library(pheatmap)  # for pretty heatmap
library(viridis) # for awesome color pallette
library(kableExtra) # for better markdown tables
library(ggpubr) # for stats on figures

## load user-written functions 
source("functions_behavior.R")
source("figureoptions.R")

## set output file for figures 
knitr::opts_chunk$set(fig.path = '../figures/01_behavior/')
```

## Sample sizes

The 'treatment' column describes the four behavioral treatment groups.  
The 'TrainSessionCombo' column describes the behvioral training sessions. Here I filter by a single session to calculte the number of mice. 

```{r wrangledata, message=F}
## import output from video tracker program 
behavior <- read.csv("../data/01_behaviordata.csv", header = T)

# rename to match RNAseq data, select useful variables
behavior <- behavior %>%
  mutate(treatment = fct_recode(APA2,
                                "standard.yoked" = "YokedSame",
                                "standard.trained" = "Same",
                                "conflict.yoked" = "YokedConflict",
                                "conflict.trained" = "Conflict")) %>%
  mutate(training = fct_collapse(treatment,
                                      trained = c("standard.trained", "conflict.trained"),
                                      yoked = c("standard.yoked", "conflict.yoked"))) %>%
  select(ID,Day,treatment, training,TrainSessionCombo,TrainSessionComboNum, ShockOnOff, PairedPartner,
         SdevSpeedArena:Speed2) %>%
  arrange(ID) 

# set levels
behavior$treatment <- factor(behavior$treatment, levels = c("standard.yoked", "standard.trained",
                                                          "conflict.yoked", "conflict.trained"))
behavior$training <- factor(behavior$training, levels = c("yoked", "trained"))

# sample sizes
behavior %>% 
  filter(TrainSessionCombo == "Hab") %>%
  select(treatment)  %>%  summary()

head(behavior)
```

## Number of shocks

The values in the column "NumShock" are actually measures of the number of entraces into the shock zone. Because, that's what the software records. For standard.trained and conflict.trained animals, the number of shocks equals equals the number of entraces. However, for yoked individuals, the number of entrances does not equal the number of shocks. For them, the number of shocks is equal to their standard.trained or conflict.trained trained partner. 

```{r shockentrplot, width=3.5, height=2.45}
# supset beahvior to keep only factors and num shocks
numshocks <- behavior %>%
  select(ID, TrainSessionCombo, treatment, NumShock) 

# widen datafram, and sum total
numshocks <- spread(numshocks, key=TrainSessionCombo, value= NumShock)
numshocks$sums <- rowSums(numshocks[sapply(numshocks, is.numeric)])
head(numshocks)

# delete values for yoked animals
numshocks <- numshocks %>%
  filter(treatment %in% c("standard.trained", "conflict.trained")) %>%
  droplevels()

# create a tempdataframe with dupclicate values for yoked
numshockstemp <- numshocks
levels(numshockstemp$treatment) 
levels(numshockstemp$treatment) <- c("standard.yoked","conflict.yoked")
levels(numshockstemp$treatment) 

# combine the two and plot

realnumshocks <- rbind(numshocks, numshockstemp)
levels(realnumshocks$treatment) 

realnumshocks$treatment <- factor(realnumshocks$treatment, levels = c("standard.yoked", "standard.trained", "conflict.yoked", "conflict.trained"))
levels(realnumshocks$treatment) <- c("standard\nyoked", "standard\ntrained", "conflict\nyoked", "conflict\ntrained")

realnumshocks %>%
  dplyr::group_by(treatment) %>%
  dplyr::summarise(meanshocks = mean(sums, na.rm = TRUE))

# define what levels to compare for stats

a <- ggplot(realnumshocks, aes(x = treatment, y = sums, fill = treatment)) +
  geom_boxplot(outlier.size = 0.5) +
  theme_ms() +
  scale_fill_manual(values = colorvalAPA00,
                    name = NULL) +
  labs(x = "treatment", subtitle = " ", y = "Total footshocks") +
    theme(axis.text.x=element_text(angle=60, vjust = 1, hjust = 1),
          legend.position = "none") 
a
```

# Vizualizing Mean and Standard error for num entrace and time 1st entrance

To make the point and line graphs, I must create and join some data frames, then I have a function that makes four plots with specific titles, y labels and limits.

```{r fourmeasures, fig.width= 6.65, fig.height=2}
dfb <- behavior %>%
  dplyr::group_by(treatment, TrainSessionComboNum) %>%
  dplyr::summarise(m = mean(NumEntrances), 
                   se = sd(NumEntrances)/sqrt(length(NumEntrances))) %>%
  dplyr::mutate(measure = "Number of target zone entrances")

dfc <- behavior %>%
  dplyr::group_by(treatment, TrainSessionComboNum) %>%
  dplyr::mutate(minutes = Time1stEntr/60) %>%
  dplyr::summarise(m = mean(minutes), 
                   se = sd(minutes)/sqrt(length(minutes))) %>%
  dplyr::mutate(measure = "Time to 1st target zone entrance (min)")

dfd <- behavior %>%
  dplyr::group_by(treatment, TrainSessionComboNum) %>%
  dplyr::summarise(m = mean(pTimeTarget), 
                   se = sd(pTimeTarget)/sqrt(length(pTimeTarget))) %>%
  dplyr::mutate(measure = "Proportion of time in target zone")

fourmeasures <- rbind(dfb,dfc,dfd)
head(fourmeasures)

# see https://cran.r-project.org/web/packages/cowplot/vignettes/shared_legends.html for share legends


b <- meansdplots(dfb, "Number of entrances" ,  c(0,10,20,30), c(0, 35)) + theme(legend.justification = "center")
c <- meansdplots(dfc, "Latency to 1st entrance (min)",  c(0,2,4,6,8), c(0, 8))
d <- meansdplots(dfd, "Prop. time in 60\u00b0 sector", c(0,.12,.25,.37), c(0, .37 ))

fourplots <- plot_grid(a + theme(legend.position="none"),
           b + theme(legend.position="none"),
           c + theme(legend.position="none"),
           d + theme(legend.position="none"),
           #align = 'vh',
           labels = c("(a)", "(b)", "(c)", "(d)"),
           nrow = 1,
           label_size = 8
           )
fourplots

pdf(file="../figures/01_behavior/fourmeasures.pdf", width=6.65, height=2)
plot(fourplots)
dev.off()

pdf(file="../figures/figure_1d.pdf", width=6.65, height=2)
plot(fourplots)
dev.off()

```



## Hierarchical clusering of time series behavioral data

Here I use heirarhical cluster to identify patterns in the behavioral data. On the y axis see three distinct clusters of behaviors that are 1) higher in trained animals, 2) higher in yoked animals, and 3) measures of speed. 

```{r pheatmap2,  message=FALSE}
## create scaled data frame
behavior_slim_heat <- behavior_slim %>%
  filter(TrainSessionCombo != "Hab")

behavior_slim_heat$RayleigAngle <- NULL
behavior_slim_heat$PolarMinBin <- NULL
scaledaveragedata <- as.data.frame(makescaledaveragedata(behavior_slim_heat))

## make annotation df and ann_colors for pheatmap
ann_cols <- as.data.frame(makecolumnannotations2(scaledaveragedata))
ann_colors = ann_colors_treatment

# set color breaks
paletteLength <- 30
myBreaks <- c(seq(min(scaledaveragedata), 0, length.out=ceiling(paletteLength/2) + 1), 
              seq(max(scaledaveragedata)/paletteLength, max(scaledaveragedata), length.out=floor(paletteLength/2)))

## pheatmap for markdown
pheatmap(scaledaveragedata, show_colnames=F, show_rownames = T,
         annotation_col=ann_cols, 
         annotation_colors = ann_colors,
         treeheight_row = 0, treeheight_col = 50,
         border_color = "grey60" ,
         color = viridis(30, option = "D"),
         clustering_method="average",
         breaks=myBreaks,
         clustering_distance_cols="correlation" ,
         clustering_distance_rows = "correlation"
         )

# pheatmapfor adobe
pheatmap(scaledaveragedata, show_colnames=F, show_rownames = F,
         annotation_col=ann_cols, annotation_colors = ann_colors,
         annotation_names_col = F,
         treeheight_row = 0, treeheight_col = 15,
         fontsize = 6, 
         border_color = "grey60" ,
         color = viridis(30),
          width = 3, height = 2,
         clustering_method="average",
         breaks=myBreaks,
         clustering_distance_cols="correlation",
         filename = "../figures/01_behavior/pheatmap2.pdf",
         legend = TRUE,
         annotation_legend = FALSE
         )

```


### Principle component analysis 

Next, I next reduced the dimentionality of the data with a PCA anlaysis. 

```{r PCA}

levels(behavior$treatment) <-  c("standard.yoked" ,"standard.trained", "conflict.yoked", "conflict.trained")

dataforpca <- behavior %>%
  filter(TrainSessionCombo != "Hab")

longdata <- makelongdata(dataforpca)

Z <- longdata[,3:322]
Z <- Z[,apply(Z, 2, var, na.rm=TRUE) != 0]
pc = prcomp(Z, scale.=TRUE)
loadings <- pc$rotation
scores <- pc$x

scoresdf <- makepcadf(dataforpca) #create the df of pcas
rotationdf <- mkrotationdf(dataforpca) #loadings for specific factors

behaviormatrix <- behavior[c(20:58)]  # for 2nd pca analysis
scoresdf$PC1 <- scoresdf$PC1 * -1
scoresdf$treatment <- factor(scoresdf$treatment, levels = c("standard.yoked" ,"standard.trained", "conflict.yoked", "conflict.trained"))
levels(scoresdf$treatment) <-  c("standard yoked" ,"standard trained", "conflict yoked", "conflict trained")


## data wraningly for pca anlysis
behaviormatrix %>% 
  scale() %>%                 # scale to 0 mean and unit variance
  prcomp() ->                 # do PCA
  pca                         # store result as `pca`
percent <- round(100*pca$sdev^2/sum(pca$sdev^2),2)
perc_data <- data.frame(percent=percent, PC=1:length(percent))
res.pca <- prcomp(behaviormatrix,  scale = TRUE)

# plot of percent contribution
ggplot(perc_data, aes(x=PC, y=percent)) + 
  geom_bar(stat="identity") + 
  geom_text(aes(label=round(percent, 2)), size=4, vjust=-.5) + 
  xlim(0, 10)

# PCA with contributions
res.pca <- prcomp(behaviormatrix, scale = TRUE)
fviz_pca_var(res.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE,     # Avoid text overlapping
             select.var = list(contrib = 8))


## print anova and TukeyHSD stats for first 6 PCs
j <- 0
for (i in (scoresdf[,c(1:6)])){
  j <- j+1
  print(paste("PC", j, sep = " "))
  myaov <- aov(i ~ treatment, data=scoresdf)
  print(summary(myaov))
  print(TukeyHSD(myaov, which = "treatment"))
}


pca12elipse <- ggplot(scoresdf, aes(PC1,PC2, color=treatment)) +
    geom_point(size=2.5, alpha = 0.7) +
    xlab(paste0("PC 1: ", percent[1],"% variance")) +
    ylab(paste0("PC 2: ", percent[2],"% variance")) +
    stat_ellipse(level = 0.95, (aes(color=treatment)),size=0.25) + 
    scale_colour_manual(values=c(colorvalAPA00)) + 
    theme_cowplot(font_size = 7, line_size = 0.25) +
    theme(legend.position="none") 
pca12elipse

pdf(file="../figures/01_behavior/pca12elipse.pdf",  width=2, height=2)
plot(pca12elipse)
dev.off()

pcalegend <- ggplot(scoresdf, aes(PC1,PC2, color=treatment)) +
    geom_point(size=2.5, alpha = 0.7) +
    xlab(paste0("PC 1: ", percent[1],"% variance")) +
    ylab(paste0("PC 2: ", percent[2],"% variance")) +
    stat_ellipse(level = 0.95, (aes(color=treatment)),size=0.25) + 
    scale_colour_manual(values=c(colorvalAPA00)) + 
    theme_cowplot(font_size = 7, line_size = 0.25) +
    theme(legend.position="bottom",
          legend.title=element_blank()) 
pcalegend

pdf(file="../figures/01_behavior/pcalegend.pdf",  width=4, height=2)
plot(pcalegend)
dev.off()

```

### Comparing standard.trained and conflict.trained behaviors during the T4/C1 training session

```{r T4consistentconflict}
filtered <- behavior_slim %>% filter(TrainSessionCombo == "T4_C1", APA != "control") 
exp_factors <- as.data.frame(filtered[,1])
exp_nums <- filtered[,c(4:42)]
exp_factors$treatment <- factor(filtered$treatment, levels = c("standard trained", "conflict trained"))
head(exp_factors)

# Levene's test for normality
#for(y in names(exp_nums)){
#  ymod <- leveneTest(exp_nums[[y]] ~ exp_factors$treatment)
#  cat(paste('\nDependent var:', y, '\n'))
#  print(ymod)
#}

# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# *** Speed1, Path2ndEntr, Time2ndEntr, Path2ndEntr, Time2ndEntr
# ** Path1stEntr, Time1stEntr
# *  Max50.RngHiBin ,  PolarMaxBin  , PolarMinVal, RayleigAngle, pTimeCW, pTimeOPP,
# .  Speed2, Min50.RngLoBin , TimeTarget, NumShock, NumEntrances
#    AnnularKurtosis, AnnularSkewnes, AnnularSd, AnnularMaxBin, AnnularMaxVal, AnnularMinBin, AnnularMinVal, Max50.RngLoBin, RayleigLength PolarMaxVal, Min50.RngHiBin , PolarMinBin, PolarSdVal, PolarAvgVal, RayleigLength, pTimeTarget, Speed2ndEntr, MaxTimeAvoid, Dist1stEntr.m, Speed1stEntr.cm.s, Linearity.Arena, SdevSpeedArena

for(y in names(exp_nums)){
  ymod <- wilcox.test(exp_nums[[y]] ~ exp_factors$treatment )
  cat(paste('\nDependent var:', y, '\n'))
  print(ymod)
}

# *** Path2ndEntr 
# **  Speed2, PolarMinVal, pTimeOPP, pTimeTarget, TimeTarget, Time2ndEntr, NumShock
# **  Dist1stEntr.m., Path1stEntr , Time1stEntr, NumEntrances
# *   PolarSdVal, PolarAvgVal 
# .    
#     Speed1, AnnularKurtosis, AnnularSkewnes, AnnularSd, AnnularAvg, AnnularMaxBin,
#     AnnularMaxVal, AnnularMinBin, AnnularMinVal, Max50.RngHiBin , PolarMaxBin, 
#     PolarMaxVal, Min50.RngHiBin, Min50.RngLoBin, PolarMinBin, RayleigAngle
#     RayleigLength, pTimeCW, pTimeCCW, Speed2ndEntr, MaxTimeAvoid, Speed1stEntr.cm.s., #     Linearity.Arena., SdevSpeedArena 
 
par(mfrow=c(3,3))
for(y in names(exp_nums)){
  ymod <- boxplot(exp_nums[[y]] ~ exp_factors$treatment,
               main = y,
               xlab = "T4/C1")
}


```

### Comparing standard.trained and conflict.trained behaviors during the T6/C3 training session

```{r T6consistentconflict}
filtered <- behavior_slim %>% filter(TrainSessionCombo == "T6_C3", APA != "control") 
exp_factors <- as.data.frame(filtered[,1])
exp_nums <- filtered[,c(4:42)]
exp_factors$treatment <- factor(filtered$treatment, levels = c("standard trained", "conflict trained"))

for(y in names(exp_nums)){
  ymod<- wilcox.test(exp_nums[[y]] ~ exp_factors$treatment )
  cat(paste('\nDependent var:', y, '\n'))
  print(ymod)
}

# Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
# ***  
# **  PolarAvgVal,
# *   Speed1stEntr.cm.s. 
# .   PolarSdVal,   
#     Speed2, Speed1, AnnularKurtosis, AnnularSkewnes, AnnularSd,
#     AnnularAvg, AnnularMaxBin, AnnularMaxVal, AnnularMinBin, AnnularMinVal
#     Max50.RngHiBin, Max50.RngLoBin, PolarMaxBin, PolarMaxVal, Min50.RngHiBin   
#     Min50.RngLoBin, PolarMinBin, PolarMinVal, RayleigAngle, RayleigLength,
#     pTimeCW, pTimeOPP, pTimeCCW, pTimeTarget, TimeTarget, Speed2ndEntr, 
#     Path2ndEntr, Time2ndEntr, MaxTimeAvoid, NumShock, Dist1stEntr.m. 
#     Path1stEntr, Time1stEntr, NumEntrances, Linearity.Arena., SdevSpeedArena

par(mfrow=c(3,3))
for(y in names(exp_nums)){
  ymod <- boxplot(exp_nums[[y]] ~ exp_factors$treatment,
               main = y,
               xlab = "T6/C3")
}
```




```{r writefiles}
write.csv(behavior, file = "../data/01a_behavior.csv", row.names = FALSE)
write.csv(fourmeasures, file = "../data/01a_fourmeasures.csv", row.names = FALSE)
write.csv(scoresdf, file = "../data/01a_scoresdf.csv", row.names = FALSE)
write.csv(rotationdf, file = "../data/01a_rotationdf.csv", row.names = TRUE)
write.csv(behaviormatrix, file = "../data/01a_behaviormatrix.csv", row.names = TRUE)
```
