---
title: "Behavior Data Analysis"
author: "Rayna M Harris"
date: "January 14, 2017"
output:
  md_document:
    variant: markdown_github
---

After wrangling the behaivoral data in the previous script ([01a_beahvior_create_dfs.Rmd](./01a_beahvior_create_dfs.Rmd)), conducted the analyses descirbed in this scipt. All plots are generate as **.png** files for markdown viewing and as **.pdf** files for incorporation to Adobe Illustrator.  

<img src="../figures/figures-01.png" width="1370" />

```{r setup, message=F, warning=F}
library(ggplot2) ## for awesome plots!
library(cowplot) ## for some easy to use themes
library(plyr)
library(dplyr) ## for filtering and selecting rows
library(factoextra)  ##pca with vectors
library(car) ## stats
library(superheat) # for kmeans clustered heatmap
library(pheatmap)  # for pretty heatmap
library(viridis) # for awesome color pallette
library(reshape2) ## for melting dataframe
library(tidyr) ## for respahing data


## load user-written functions 
source("functions_behavior.R")
source("figureoptions.R")

## set output file for figures 
knitr::opts_chunk$set(fig.path = '../figures/01_behavior/')
```

To help make production of these figures more reproducible, I first import some intermediate data files that I cleaned and manipulated for data vizualization. I also relevel factors here to overide the defalut alphabetical plotting. 

```{r data, message=F}
behavior <- read.csv("../data/01a_behavior.csv", header = T)
threeplots <- read.csv("../data/01a_threeplots.csv", header = T)
scoresdf <- read.csv("../data/01a_scoresdf.csv", header = T)
rotationdf <- read.csv("../data/01a_rotationdf.csv", header = T, row.names = 1)
behaviormatrix <- read.csv("../data/01a_behaviormatrix.csv", header = T, row.names = 1)

#set factor levels
scoresdf$APA <- NULL
scoresdf$APA2 <- factor(scoresdf$APA2, levels = c("yoked-consistent" ,"consistent", "yoked-conflict", "conflict"))
threeplots$APA2 <- factor(threeplots$APA2, levels = c("yoked-consistent" ,"consistent", "yoked-conflict", "conflict"))
threeplots$measure <- factor(threeplots$measure, levels = c("Number of Entrances" , "Max Avoidance Time", "Speed"))
```

## Figure 1B: Standard vizualization of mean avoidance beavior
First, I visualze the group mean and standard error for the time it takes before an individual mouse enters the spatial region marked "schock zone" or equivilent (Fig. 1A).

```{r behaviorplots}

behaviorwrap <- ggplot(threeplots, aes(x=, TrainSessionComboNum, y=m, color=APA2)) + 
    geom_errorbar(aes(ymin=m-se, ymax=m+se, color=APA2), width=.1) +
    geom_point(size = 2) +
   geom_line() +
   scale_y_continuous(name= NULL) +
    scale_x_continuous(name="Training Session", 
                       breaks = c(1, 2, 3, 4, 5, 6, 7, 8, 9),
                       labels = c( "Hab.", "T1", "T2", "T3",
                                   "Retest", "T4", "T5", "T6", "Reten.")) +
  theme_cowplot(font_size = 8, line_size = 0.25) +
  #background_grid(major = "y", minor = "y") +
  scale_color_manual(values = colorvalAPA00)  +
  theme(legend.position=c(0.7, 0.8))  +
  theme(legend.title=element_blank()) +
  theme(legend.position="none") +
  facet_wrap(~measure, ncol=1, scales = "free_y")
behaviorwrap

pdf(file="../figures/01_behavior/threebehaviors.pdf", width=3.25, height=3.75)
plot(behaviorwrap)
dev.off()
```


## Hierarchical clusering of time series behavioral data

Here I use heirarhical cluster to identify patterns in the behavioral data. On the y axis see three distinct clusters of behaviors that are 1) higher in trained animals, 2) higher in yoked animals, and 3) measures of speed (Fig. 1C). 

```{r pheatmap2,  message=FALSE, results='hide'}
## make annotation df and ann_colors for pheatmap
behavior$RayleigAngle <- NULL
behavior$PolarMinBin <- NULL
scaledaveragedata2 <- as.data.frame(makescaledaveragedata2(behavior))

# create a rubric for the color coding and load the colors from figureoptions.R
df2 <- as.data.frame(makecolumnannotations2(scaledaveragedata2))
ann_colors = ann_colors9  # includes color for session & APA

# set color breaks
paletteLength <- 30
myBreaks <- c(seq(min(scaledaveragedata2), 0, length.out=ceiling(paletteLength/2) + 1), 
              seq(max(scaledaveragedata2)/paletteLength, max(scaledaveragedata2), length.out=floor(paletteLength/2)))

## pheatmap for markdown
pheatmap(scaledaveragedata2, show_colnames=T, show_rownames = T,
         annotation_col=df2, 
         annotation_colors = ann_colors,
         treeheight_row = 0, treeheight_col = 50,
         border_color = "grey60" ,
         color = viridis(30),
         clustering_method="average",
         breaks=myBreaks,
         clustering_distance_cols="correlation" ,
         clustering_distance_rows = "correlation"
         )

# pheatmapfor adobe
pheatmap(scaledaveragedata2, show_colnames=F, show_rownames = F,
         annotation_col=df2, annotation_colors = ann_colors,
         annotation_names_col = F,
         treeheight_row = 0, treeheight_col = 25,
         fontsize = 6, 
         border_color = "grey60" ,
         color = viridis(30),
          width = 3.25, height = 3.5,
         clustering_method="average",
         breaks=myBreaks,
         clustering_distance_cols="correlation",
         filename = "../figures/01_behavior/pheatmap2.pdf",
         legend = TRUE,
         annotation_legend = FALSE
         )

```


### Figure 1D1 and 1D2: Principle component analysis 
Next, I next reduced the dimentionality of the data with a PCA anlaysis. PC1 explains 35% of the variation in the data. All other PCs explain less than 10% of the variation.

```{r PCA}
## data wraningly for pca anlysis
behaviormatrix %>% 
  scale() %>%                 # scale to 0 mean and unit variance
  prcomp() ->                 # do PCA
  pca                         # store result as `pca`
percent <- round(100*pca$sdev^2/sum(pca$sdev^2),2)
perc_data <- data.frame(percent=percent, PC=1:length(percent))
res.pca <- prcomp(behaviormatrix,  scale = TRUE)

# plot of percent contribution
ggplot(perc_data, aes(x=PC, y=percent)) + 
  geom_bar(stat="identity") + 
  geom_text(aes(label=round(percent, 2)), size=4, vjust=-.5) + 
  xlim(0, 10)

```

### Figure 1D1: 35% of behaivor variance (PC1) separates yoked from trained 
PC1 encompases differences between yoked trained indivdual but does not significantly differ between consistent and conflict trained aniamls. To confirm statistical significance of this visual pattern, we conducted a two-way treatment x region ANOVA and confirmed a significant effect of region (F2,31= 101.39; p = 2.5e-14). Post hoc Tukey tests confirmed conflict = consistent < control). The major contibutors to this variation are number of shocks and distance to first entrance.

```{r PCAplots}
## statistics
aov1 <- aov(PC1 ~ APA2, data=scoresdf)
summary(aov1) # p = 1.01e-13
TukeyHSD(aov1, which = "APA2") # p<< 0.001 for both control comparisions

aov2 <- aov(PC2 ~ APA2, data=scoresdf)
summary(aov2) # p = 0.0295 *
TukeyHSD(aov2, which = "APA2") # p > 0.05

summary(aov(PC3 ~ APA2, data=scoresdf)) # p = 0.117
TukeyHSD((aov(PC3 ~ APA2, data=scoresdf)), which = "APA2") 

summary(aov(PC4 ~ APA2, data=scoresdf))

summary(aov(PC5 ~ APA2, data=scoresdf))

summary(aov(PC6 ~ APA2, data=scoresdf))
TukeyHSD((aov(PC6 ~ APA2, data=scoresdf)), which = "APA2") # p > 0.05

scoresdf$wrap <- "Principal Component Analyses of Behavior"

pca12 <- ggplot(scoresdf, aes(PC1,PC2, color=APA2)) +
    geom_point(size=3, alpha = 0.7) +
    xlab(paste0("PC 1: ", percent[1],"% variance")) +
    ylab(paste0("PC 2: ", percent[2],"% variance")) +
    scale_colour_manual(values=c(colorvalAPA00)) + 
    theme_cowplot(font_size = 8, line_size = 0.25) +
      theme(legend.position="none") +
  facet_wrap(~wrap)
pca12

pdf(file="../figures/01_behavior/pca12.pdf",  width=1.5, height=1.5)
plot(pca12)
dev.off()

pca16 <- ggplot(scoresdf, aes(PC1,PC2, color=APA2)) +
    geom_point(size=3, alpha = 0.7) +
    xlab(paste0("PC 1: ", percent[1],"% variance")) +
    ylab(paste0("PC 2: ", percent[2],"% variance")) +
    stat_ellipse(level = 0.95, (aes(color=APA2)),size=0.25) + 
    scale_colour_manual(values=c(colorvalAPA00)) + 
    theme_cowplot(font_size = 8, line_size = 0.25) +
      theme(legend.position="none") +
  facet_wrap(~wrap)
pca16

pdf(file="../figures/01_behavior/pca16.pdf",  width=3.25, height=2.25)
plot(pca16)
dev.off()

pca12 <- ggplot(scoresdf, aes(PC1,PC2, color=APA2)) +
    geom_point(size=3, alpha = 0.7) +
    xlab(paste0("PC 1: ", percent[1],"% variance")) +
    ylab(paste0("PC 2: ", percent[2],"% variance")) +
    stat_ellipse(level = 0.95, (aes(color=APA2)),size=0.25) + 
    scale_colour_manual(values=c(colorvalAPA00)) + 
    theme_cowplot(font_size = 8, line_size = 0.25) +
      theme(legend.position="none") +
  facet_wrap(~wrap)
pca12

library(factoextra)
res.pca <- prcomp(behaviormatrix, scale = TRUE)
fviz_eig(res.pca)
fviz_pca_var(res.pca,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE,     # Avoid text overlapping
             select.var = list(contrib = 10))
fviz_pca_biplot(res.pca, label ="var")
```


Here are some stats modeling combinatorail PCs. I'm really not sure if this makes sense. I should probabaly model some behavior time interaction....

```{r linearmodel}

lm1 <- lm(PC1~APA2, data=scoresdf)
summary(lm1)

lm16 <- lm(PC1+PC6~APA2, data=scoresdf)
summary(lm16)

lm136 <- lm(PC1+PC3+PC6~APA2, data=scoresdf)
summary(lm136)

```

## getting file name for a time spent heatmap

```{r forandre}
y <- behavior %>%
  distinct(ID, APA2)
x <- read.csv("~/Github/BehavEphyRNAseq/data/behavior/APA_2013-2016.csv", header = T)
x <- x %>%
  distinct(ID, filename)

z <- inner_join(x,y)
write.csv(z, "filnames.csv", row.names = F)
```

## anova conflict

```{r}
slim1 <- behavior[,c(15,16,14,20:59)]
slim2 <- slim1 %>% filter(TrainSessionCombo == "T4_C1", APA != "control") 
APA2 <- slim2[,1]
slim3 <- slim2[,c(4:43)]

for(y in names(slim3)){
  ymod<- summary(aov(slim3[[y]] ~ APA2 ))
  cat(paste('\nDependent var:', y, '\n'))
  print(ymod)
}

for(y in names(slim3)){
  ymod <- t.test(slim3[[y]] ~ APA2 )
  cat(paste('\nDependent var:', y, '\n'))
  print(ymod)
}

# *** Time1stEntrLog, pTimeTarget, TimeTarget, Path2ndEntr, Time2ndEntr, NumEntrances
# **  Speed2, PolarSdVal, Dist1stEntr.m, Time1stEntr
# *   PolarMinVal, PolarAvgVal, pTimeOPP, Speed2ndEntr
# .   Speed1, pTimeCW
# not AnnularKurtosis, AnnularSkewnes, AnnularSd, AnnularAvg, AnnularMinBin, AnnularMaxBin, Max50.RngHiBin, Max50.RngLoBin, PolarMaxBin, PolarMaxVal, Min50.RngHiBin, Min50.RngLoBin, PolarMinBin, RayleigAngle, pTimeCCW, MaxTimeAvoid, Linearity.Arena, SdevSpeedArena


hist(slim3$Time1stEntrLog)
boxplot(slim3$Time1stEntrLog ~ APA2)
summary(aov(slim3$Time1stEntrLog ~ APA2)) 
t.test(slim3$Time1stEntrLog ~ APA2)

```